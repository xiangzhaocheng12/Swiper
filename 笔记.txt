Django 中的类字典对象
request.GET
request.POST
request.FILES
request.session



Flase 中的类字典对象
request.args
request.form
request.files
session
---------------------
1. cookie  和session
  # 默认的 HTTP协议的端口是80，默认的HTTPS协议的端口号是443
2. 请求在Django 中执行的过程
    一. 从用户点击链接到页面显示的全过程？
        ① 点击   http://www.baidu.com
        ② 客户端进行 DNS 解析   www.abcd.com  -> 11.22.33.44
            # HTTP 协议是建立在 TCP 协议上的 "短链接"  协议： 只通信一次, 然后就断掉了
            # TCP 是全双工协议
        ③ 客户端和服务器简历 TCP 连接
            三次握手:
            1. client -> SYN -> server
            2. client <- ACK + SYN <- server
            3. client ->       ACK -> server
        ④ 浏览器构造'请求报文'
        ⑤ 浏览器将'请求报文'发送到服务器
    二. Django 中的操作
        ① Django 的  HTTP Server 接收客户端的请求报文
            # Http Server 用来：
            #    1. 接收和发送数据
            #    2. 建立和断开连接
        ② WSGI 模块将 "请求报文" 解析并封装成 HttpRequest 对象
        ------------------------------------->  process_request
        ③ 进行 URL 匹配, 得到对应的视图函数
        ------------------------------------->  process_view
        ④ 视图函数进行处理

            |-1. 获取、检查参数
            |-2. 进行业务逻辑处理(缓存、数据库、运算)
            |-3. 将结果数据转化成前端需要的格式(模板渲染, 封装 JSON)
            |---------------------------------->  process_template_response(这一层的中间件用的极少)
            |-4. 将结果封装成 HttpResponse 对象n,,
            +--------------------------------------> 仅当出现异常时触发 process_exception


            --------------------------------->  process_response
        ⑤ WSGI 将 HttpResponse对象转化成"响应报文"
        ⑥ Http Server 将"响应报文" 传给客户端
        ⑥ HTTP Server 断开与客户端的连接
            1. server -> FIN ->client
            # 为什么不能把四次挥手的过程有化成三次挥手的过程？
            2. server <- ACK <- client

            中间的时间:等待传输结束, 客户端检查是否有丢包

            3. server <- FIN <- client
            4. server -> ACK -> client
        ⑦ 客户端接收"响应报文"
        ⑧ 客户端解析、渲染、呈现页面


索引
    哈希索引
        底层使用的是哈希表, 通过哈希表上面一个槽的位置来进行匹配
        时间复杂度: O(1)

    select * from user where name like '张%';   # 此时可以使用索引
    select * from user where name like '%张';   # 此时无法使用索引




    B 树, B+树

定位
    GPS
    基站定位
    WI-FI
    IP 定位
经度 -180~ 180
维度 -90 ~ 90

GEO Hash : 精度不高, 模糊匹配的方式


--------------------------------------------
Day06:
git
    branch
    master
    develop
    feature

    pull request -> 代码审核(新人如果三次代码审核都不行, 基本上就凉了)
user
    发短信(跟第三方平台的对接, 关键是看平台的接口文档, Celery异步[还可以做定时])
    登陆(中间件、session、Django 源码)
    查看交友资料信息(user表和profile表一对一的关系、外键、property)
    修改个人信息(Form、ModelForm)
    七牛云
        1. 客户端 -> 服务器, 获取 token
        2. 客户端 -> 七牛云: 携带 Token 上传头像
        3. 七牛云 -> 访问服务器:七牛云的回调(回调服务器, 服务器保存结构)
        4. 七牛云 -> 客户端:通知客户端上传成功
social
    推荐:
        1. 创建机器人: 独立脚本如何调用 Django 项目中的模块
        2. Django ORM
        3. 企业中的一些推荐
    '喜欢'接口:联合唯一, 联合主键(底层使用的都是联合唯一的索引来操作的)
        class Meta:
            unique_together = ('uid', 'sid')

        联合唯一
        create table swiped(
            uid int,
            sid int,
            unique(uid,sid)
        )
        联合主键
        create table swipped(
            uid it,
            sid int,
            primary key (uid, sid),
        )


python 垃圾会回收机制
- 引用计数
- 标记清除
- 分代收集

- - 引用计数:
a = 1234567
b = a
    python 会针对每个变量进行记录, 当前的引用计数会减一
del b   # 此时该变量会减少 1

- - 引用计数所不能回收的:
a = [1,2,3]
b = [3,2,1]
a.append(a)
b.append(a)    # 循环引用无法进行清除, 需要使用标记清除的方式

- - 分代收集:

装饰器:
def foo(func1):
    def wrapper(*args,**kwargs):

        return
    return

服务器的内存查看：
    top/htop/free

Linux 的五个命令:
    ps      grep    scp     chmod   chown

1. 查看CUP负载
top 命令:
    top - 14:15:11 up 142 days, 20:33,  6 users,  load average: 6.19, 4.39, 3.60
    load average(平均负载):   一分钟负载,     ,十分钟负载

    %Cpu0  : 83.7 us, 15.9 sy,  0.0 ni,  0.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
             user       system            idle(空闲的)
             我的服务器貌似要炸了?!

     PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND
    28077 root      10 -10  158800  47384   9840 S  9.3  2.5  14:52.31 AliYunDun
    26454 JiangCh+  20   0  214128  16996   4492 R  6.3  0.9   0:00.19 python3
    26457 JiangCh+  20   0  213556  16496   4484 R  6.3  0.9   0:00.19 python3
    12827 JiangCh+  20   0  492024  39332   5712 S  1.0  2.1   0:49.70 python

    TIME 表示实际占用CPU的时间

uptime:

2. 数据库的主从复制
    主机   <- 写入
      |
     bin_log
       从机: 产生一个线程, 把主机的日志搬运过来  relay_log
             然后把传过来的日志搬运到数据库中
             因此会产生两个线程, 一个IO进程, 一个sql线程
       从机  -> 读取
       从机  -> 读取
     读写分离

-------------------------------------------------------------------------------------
Day07
简历:
Web 项目:
    微博:
        发表
        评论、回复(id、uid、wid、cid) content
        点赞、关注

Swiper
    缓存的处理、
    状态码的处理、
    异常的处理、
    关注和被关注



App 种类: 可以将电商的功能集成到其中
- 厨艺类: 下厨房
- 教育类: 小猿搜题、作业帮
- 财经类: 雪球、同花顺
- 阅读类: 微信读书、起点、掌阅(服务器用python写的)
- 知识类: 知乎、果壳、知识星球、得到APP、极客时间
- 资讯类: 今日头条、一点
- 社区类: 豆瓣、天涯、贴吧
- 小视频: 抖音、快手
- 直播类: 斗鱼、虎牙、战旗、熊猫
- 旅游类: 穷游网、携程、马蜂窝、去哪儿、飞猪
- 健身类: Keep、悦跑圈

    - 社交类
    - 电商类
    - 游戏类

U G C:

下厨房:
    虚拟币
    浏览记录: 每次点开一个都是一个浏览记录, 一张表, 一个是uid, 一个是文章的URL
             还可以用redis做一个队列,
             一般的浏览记录都是指定保存50条左右
    充值: 跟支付宝对接
    优惠卷: 优惠卷的设置表、与用户关联的表、
        优惠卷配置表:
            id  优惠额度    满足条件    类别   商家   开始时间     结束时间
            7     20          100      生鲜         20200729    20200829
        用户得到的优惠卷:
            uid  quan_id    count(个数)
            99      7           3
            99     21
            99     39
            注意: uid和quan_id 需要联合唯一

    红包: 类似于优惠卷


    打卡:
    等级: 评论积分、打卡积分、购买积分



缓存/缓冲
    缓冲: 数据从 "高速系统" 进入 "低速系统" 时的临时存储区叫做缓冲
    缓存: 数据从 "低速系统" 进入 "高速系统" 的临时存储区叫做缓存

数据库中的数据放入 Redis 中。

Python -> Redis -> MySQL

缓存命中率: 96%  (几乎所有的数据都是在Redis中)

String:
    - set(key, value)
    - get(key)
    - mset()
    - mget()
    - incrby()
Hash
    - hset
    - hget
    - hgetall()
    - hincrby()
List
    - lpush() / rpush()
    - lpop()  / rpop()
    - lrange(key,start,end)    # key 值和
    - ltrim(key,start,end)
Set
    - r.sadd('name',value1,value2)
    - r.smembers('name')
    - r.sismember()
    - r.inter()  /   union()  /  diff()
Zset(有序集合)
    - r.zadd('game',{'ll',81,'yr':75,'yx':98, 'yxl':100,'hy':78,'mh':59})
    - r.zrange() /  r.zrevrange()  降序排行
    - r.count() / r.zrecount()
    - r.zrank() / r.zrevrank()
    - zincrby()    指定增加1

pub/sub:
    消息发布和订阅系统

--------------------------------------------------------------------------------------
Day08
缓存:
    存储资源:
        【寄存器、一级缓存、二级缓存、三级缓存】(这些都在CPU中)、内存、硬盘
    计算机的主存储设备: 内存

    Redis的运行机制：
        在启动时将硬盘中的数据加载到内存中:
        - dump rdb   redis运行过程中检查多少个key发生了修改,
                例如当五分钟发生修改了之后, 会将内存中的数据完整的镜像到rbd文件中,
                只保存最新的rdb文件。
        - aof   执行的任何操作都会在aof中进行记录。
        因此线上需要两个都开着

排行榜:
    1. 数据库
    ①将所有用户的积分保存到积分的从表
        HotRank
        --------
        uid       score
        21         2
        35         2037
        836        8347
              ...
    ②取出前50 的数据
        select * from HotRank order by score limit 50;
        (这个方式不是很好, 数据量大的时候速度过慢)

    ③-1 将前50 的数据写入到内存表中
        create table cache_hotrank(
            uid int,
            score int
        )charset = utf8mb4 engine = memory;

    ③-2 或者将前50的数据放入到Redis中

    ④ 从Redis中进行读取

    2. 完全使用Redis
        使用 zset 保存数据
        zincrby       指定增加1
        zrevrange     降序排行

支付流程:
    手机 -> App 网站
        账单号
        金额
        币种o
        商品ID
        用户ID
        {'aa':123, 'bb':123}  -> ''
        签名   拼接到数据的后面
     <- Token
手机  -> Token  -> 支付

支付宝  ->  回调   -> AppServer
                    验证订单
                    将订单标记为已完成

单元测试


----------------------------------------------
2020-7-31
如何提升并发
- Web 分布式部署
    Nginx 负载均衡的算法
- Web 并发处理能力:
    1. Gunicorn - Gevent(Python 的一个携程库)   多进程和多携程的处理方式
    2. uwsgi(比较早期)
- 缓存:
    缓存本身也可以分布式、主从
- 数据库:
- 耗时任务的异步化:
    Celery: 独立于django之外的另一个进程, 多任务多进程的异步化



GIL:
    可以使用进程数和CPU 的核心数相等或者是核心数的两倍？
    GIL 锁是为了保证Python 内部数据的安全性

from threading import Lock
    这个是线程锁, 目的是为了保证


Linux 如何找到一个文件夹下的所有 Python 文件
    法1：
        find foo/bar  -name '*.py' -set -5k -size +3k -perm 0755
        找到文件夹下面的.py 文件     小于5k      大于3k   权限为755
    法2：
        find /foo/bar | grep '*.py'
        find /foo/bar | grep -E '\.py$'    这个表示用正则表达式来匹配


分布式的分库分表
法1:通过哈希进行映射
    >>uid = b'1234567'
    >>md5(uid).hexdigest()
    b'fc4yfvybrtvrctrr...'

    >>uid = b'567887867'
    >>md5(uid).hexdigest()
    'bdbf89sd7f89fg79afsfsd'

法2: 按照余数进行数据拆分
    数据库路由算法: 按数据id 进行
    Database-0  1   8    16
    Database-1  2   9    17
    Database-2  3   10   18
    Database-3  4   11   19
    Database-4  5   12   20
    Database-5  6   13   21
    Database-6  7   14   22

    扩容过程:
        初始状态:
            只有一台机器: id % 1 = Database -0
            Database-0: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ...

        第一次扩容:
            增加一台机器: id % 2 = Database -0
            需要迁移 50% 的数据

            Database-0:  1 3 5 7 9 11 13 15 17 19
            Database-1:   2 4 6 8 10 ...

        第二次扩容:
            增加一台机器: id % 3


ObjectID 算法

    机器编号、进程编号、时间戳    随机数     序号
    拼凑不同的因子, 达到绝对唯一的特性

    优点:相较于Redis自增, 进行操作的话, 速度更快, 相差几万倍
        而且没有存储依赖
    缺点:
        整体产生的数字比较大, 并且是无序的

还有一致性哈希的方式
    可以了解了解

----------------------------
下午
服务高可用配置时常用的监控软件
    - keepalived
        通过调用脚本来进行(能力较弱)
        监控服务器进程
    - zabbix
        监控服务器 cpu、进程运行情况、内存情况等...(监控能力最强)
    - zookeeper
        调整不同机器的配置
        监控哪一台式主机, 哪一台是从机, 主机挂了之后, 通过下发配置, 进行从机提升


    KeepAlive: HTTP里面的一个协议

                ->               -> Django
    userRequest ->    负载均衡    -> Django
                ->               -> Django

多任务处理
    - 多进程: 几个G
    - 多线程: 2-3 k
    - 多协程: 400-500 b 切换快, 占用的资源少
常用的方式:
    多进程 + 多协程
        处理 CPU密集型 和 IO密集型任务
        一个django就是一个进程, 当IO 进来的时候, 就开启一个协程

    示例(上下文切换):
        当任务B 的数据没有到达的时候, 主动将解释器的控制权交给任务A(有效的切换)
            把空闲的时间都让出去,可以让CPU 的利用率更高
        taskA:--->      ------>------>------>------>------>------>----->
                  |     ^                                              |设置激活事件
                  v     |                                              |event
        taskB:    ------->                                             --->
                  yield  s.recv

        每次切换的时候向操作系统中注册一个 epoll 的事件(都已经包装在框架中了)
        按照信号激活指定的任务

WSGI 将传过来的请求报文进行数据转化, 然后发送给 WebApp


单台机器上限制并发的因素:
- 硬件
    - CUP
    - Memory
    - Bandwidth

- 软件
    - 语言本身的性能   C/C++   Go    Python
    - Linux >  Windows
    - 程序底层并发处理模型: IO多路复用   Epoll > Select/Poll
                                      基于事件    轮询
    - 最大文件描述符
    - 操作系统内核参数

pidfile   主进程的id




Echo 测试:
    - 测试的是服务器性能的极限
    - 39000 r/s

带缓存的测试: 10000 r/s 左右

带数据库的测试: 800 r/s
    最好针对每个接口都进行测试:
    还可以将 New Relic 添加到项目里面, 可以查看到系统里面请求各个部分所占时间

----------------------------------------------
项目上线
    购买云服务器
        设置主机
            入站规则:访问服务器的来源
                10.0.0.0/8: 表示10.这个地方不能改变,后面的都可以发生改变
            销毁时间:
                可以自己定时, 设置
            第一次登陆云服务器: 提示指纹, 直接yes
            创建新用户: useradd 用户名
                一般来说需要添加的选项
                    (需要将用户加到wheel 这个组里面)
                    -m 创建yonghu de zhumulu
                    -U 创建与用户同名的组
                    -s 设置新账户的登陆 shell
                    -G 设置需要给新用户添加的组名
                useradd  -rmU -G 'adm,wheel,users' -s bin/bash seamile
            设置新用户的密码:
                passwd seamile
        修改 /etc/ssh/sshd_config
        1. 将 PermitRootLogin 设置为 no
        2.

--------------------------
## shell 脚本
Shell 脚本的一些特殊行为
    1. shell 脚本会将所有输入的内容当作命令行来执行
    2. shell 会将所有的空格分隔的内容当作参数
    3. 默认认为所有的参数都是一个字符串

两个变量的相加: echo $[a + b]


----------------------------
2018-8-4
Nginx:
    正向代理
    +---------------+
    | user -> proxy |  ->  Server
    +---------------+
    - user -> proxy -> server
    - 透明代理 例如网游加速器
    - 加密代理 例如爬虫


    反向代理(给服务器去使用的)
            +--------------------------+
            |       / django-1 (chart) |
    user -> |proxy -> django-2 (Tmall) |
            |       \ django-3 (API)   |
            +--------------------------+
        一个系统里面有很多个小服务, 一个service 提供一个小的功能,
        根据不同的请求进行转发, 同时隐藏内部服务器的IP地址, 提升安全性
    负载均衡
        - 轮询: 使用DNS 轮询, 每次访问的反向代理的服务器可能都是不一样的.
        - 权重: 根据权重进行转发
        - IP Hash   根据IP值进行哈希算法, 根据哈希值匹配到某一个指定的服务器上.
                    这样子可以直接把某个用户的数据保存到一个 Django 的服务器上
        - 最小连接数
            原则: 谁的压力大, 就给谁分配的就越少, 谁的压力越小, 就给谁分配的就越大

其它的负载均衡:
    F5(硬件方面的)、LVS、Haproxy
    Nginx最慢, 但拉开的差距不大

可以只使用Gunicorn, 不使用Nginx吗?
1. 相较于Gunicorn来说, Nginx 更加安全
2. Nginx可以进行负载均衡, 而Gunicorn不行。


消息队列:
    RabbitMQ:
        可以是一个任务、也可以是一个对象
    Rocket M Q:




服务器性能评估:

DAU: 日活跃用户量    20万(不算低的)
    一个用户一天的请求量:
        类似于抖音等APP, 这些软件的粘性较大
    用户单日总请求量: 20万  * 200次 = 4000万

    衡量服务器峰值的指标:
        request per second(每秒的请求数)
        二八定律:80%的请求会在20%的时间内到达
        每天高峰时段服务器的 RPS 的值: (4000 万 * 80%)/ (86400 * 20%) = 1851.8 r/s

        此时的服务器性能最差的时候: 800 r/s


公司整体的服务器:
    bastion         堡垒机
    mon             监控
    apptest         测试机 1 台
    WebAppServer    指的就是django/Flask: 15台
    dbm60           业务数据库 8 台
        dbs61       从机
    data-rcmd       NoSQL (Redis)  11 台

    queuem          消息队列(RabbitMQ) 1 台

    worker1         任务队列 6 台
    worker2         ...
    batch1
    batch2
    ...

    log_collector   日志收集  1 台(大型公司需要更多的日志手机服务器)

    web1            额外的服务器, 例如微信小程序的服务器(2 台)
    web2
